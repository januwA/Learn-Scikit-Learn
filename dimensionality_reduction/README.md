# Dimensionality Reduction (降维)

降维是机器学习中的一项关键技术，旨在减少特征的数量，同时尽可能保留原始数据的内在结构和信息。

## 为什么要降维？

1.  **可视化**：将超过 3 维的数据投影到 2D 或 3D 空间，方便直观观察数据分布。
2.  **效率**：减少训练模型所需的计算资源和时间。
3.  **去噪**：剔除不相关的特征（噪声），提取核心信息（主成分）。
4.  **防止过拟合**：在小样本数据集上，降低维度可以减少模型的复杂度。

## 目录演示说明

### 1. PCA 手写数字投影 (`pca_digits.py`)
*   **数据集**：`load_digits` (8x8 灰度图，共 64 个特征)。
*   **方法**：**PCA (主成分分析)**。
*   **演示内容**：
    *   将 64 维特征压缩到 2 维。
    *   通过散点图观察不同数字（0-9）在低维空间是如何自动聚类的。
    *   理解 `explained_variance_ratio_`（解释方差比例）。

---

## 常用算法

| 算法 | 特点 |
| :--- | :--- |
| **PCA** | 最经典的线性降维，寻找数据方差最大的方向。 |
| **t-SNE** | 非线性降维，极度擅长将高维聚类转化为 2D/3D 可视化，保留局部结构。 |
| **TruncatedSVD** | 适用于稀疏矩阵（如词向量、TF-IDF），在 NLP 中非常有用。 |
